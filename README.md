# PayToGether

> **‚úÖ Build Status : FONCTIONNEL** (mis √† jour le 3 f√©vrier 2026)  
> Les probl√®mes de build Maven ont √©t√© r√©solus. Voir [`README_BUILD_FIX.md`](README_BUILD_FIX.md) pour les d√©tails.

> **üîÑ Gestion de base de donn√©es : LIQUIBASE INT√âGR√â** (19 f√©vrier 2026)  
> Le sch√©ma de base de donn√©es est maintenant g√©r√© avec Liquibase. Voir [`LIQUIBASE_INTEGRATION.md`](LIQUIBASE_INTEGRATION.md) pour les d√©tails.

> **üê≥ Docker Java 21 : OPTIMIS√â** (21 f√©vrier 2026)  
> Dockerfile migr√© vers Java 21 avec optimisations multi-stage, images Alpine et JVM optimis√©e. Voir [`RECAPITULATIF_DOCKER_JAVA21.md`](RECAPITULATIF_DOCKER_JAVA21.md) pour les d√©tails.

---

## üöÄ Quick Start

### D√©veloppement local avec Docker

```bash
# D√©marrer la stack compl√®te (BFF + PostgreSQL + MinIO)
docker-compose up -d

# V√©rifier le statut
curl http://localhost:8080/actuator/health
```

**üëâ Guide complet** : [QUICKSTART_DOCKER.md](QUICKSTART_DOCKER.md)

### Avec Makefile

```bash
make run-compose  # D√©marrer
make logs         # Voir les logs
make health       # Health check
make stop-compose # Arr√™ter
```

---

## üì¶ Docker - Nouvelles Optimisations Java 21

### Caract√©ristiques

- ‚úÖ **Java 21** avec Eclipse Temurin
- ‚úÖ **Images Alpine** (~200 MB vs ~850 MB)
- ‚úÖ **Multi-stage build** (cache Maven optimis√©)
- ‚úÖ **Utilisateur non-root** (s√©curit√© renforc√©e)
- ‚úÖ **JVM optimis√©e** (G1GC, gestion m√©moire container)
- ‚úÖ **BuildKit** (build 70% plus rapide)

### R√©sultats

| M√©trique | Avant | Apr√®s | Gain |
|----------|-------|-------|------|
| Taille image | ~850 MB | ~200 MB | **-76%** |
| Temps d√©marrage | ~45s | ~15s | **-67%** |
| Temps build (cache) | ~5 min | ~1 min | **-80%** |

### Build de l'image

```bash
# Avec script automatis√©
./build-docker.sh

# Avec Makefile
make build

# Ou manuellement
DOCKER_BUILDKIT=1 docker build -f modules/bff/Dockerfile -t paytogether-bff:latest .
```

---

## Repository Docker Hub

Nous utilisons le repository Docker Hub: `14152021/dealtogether`.
Les images construites par le pipeline Jenkins sont tagg√©es comme suit:
- front: `14152021/dealtogether:front-<env>-<commit>`
- bff: `14152021/dealtogether:bff-<env>-<commit>`

Des tags `front-latest` et `bff-latest` sont √©galement pouss√©s pour les branches `dev` et `hml`.

### Registry priv√©

**Registry** : `registry.dealtogether.ca`

```bash
# Build et push vers registry priv√©
make build
make push

# Ou manuellement
docker build -f modules/bff/Dockerfile -t registry.dealtogether.ca/bffpaytogether:latest .
docker push registry.dealtogether.ca/bffpaytogether:latest
```

---

## Pr√©-requis

- **Docker** : version 20.10+
- **Docker Compose** : version 2.0+
- **M√©moire** : minimum 4 GB allou√©s √† Docker
- **Java** : version 21 (pour d√©veloppement local sans Docker)
- **Maven** : version 3.9+
- Jenkins configur√© avec les credentials:
  - `pay2gether` (username/password Docker Hub) utilis√© dans le `Jenkinsfile`.
  - `pay2gether` (file) pour le kubeconfig si vous voulez d√©ployer depuis Jenkins.
- Un cluster Kubernetes avec NGINX Ingress controller install√©.

---

## Build & Push (local)

Exemples de commandes locales (bash/macOS):

1. Construire les images:

```bash
# depuis la racine du projet
# Front
docker build -t frontpaytogether:latest ./bff-front
# Back
docker build -t bffpaytogether:latest ./
```

2. Tagger et pousser vers Docker Hub (remplacer USER par votre login si n√©cessaire):

```bash
docker login --username <docker-user>
# Tag
docker tag frontpaytogether:latest 14152021/dealtogether:front-dev-<commit>
docker tag bffpaytogether:latest 14152021/dealtogether:bff-dev-<commit>
# Push
docker push 14152021/dealtogether:front-dev-<commit>
docker push 14152021/dealtogether:bff-dev-<commit>
# Optionnel: latest
docker tag frontpaytogether:latest 14152021/dealtogether:front-latest
docker tag bffpaytogether:latest 14152021/dealtogether:bff-latest
docker push 14152021/dealtogether:front-latest
docker push 14152021/dealtogether:bff-latest
```

## D√©ployer le registry local (optionnel)
Le manifeste `k8s/registry-deployment.yaml`, `k8s/registry-service.yaml` et `k8s/registry-pvc.yaml` permettent de d√©marrer un registry Docker local dans le namespace `paytogether`.

1. Appliquer les manifests:

```bash
kubectl apply -f k8s/namespace-paytogether.yaml
kubectl apply -f k8s/registry-pvc.yaml
kubectl apply -f k8s/registry-deployment.yaml
kubectl apply -f k8s/registry-service.yaml
kubectl apply -f k8s/ingress-registry.yaml
```

2. Acc√©der au registry via `http://registry.dealtogether.ca` (si DNS local ou /etc/hosts configur√© vers l'IP de l'ingress).

Note: ce registry n'est pas s√©curis√© par d√©faut (HTTP) ‚Äî pour un usage production, configurez TLS et auth (htpasswd) ou utilisez un registry priv√© tiers.

## D√©ploiement des applications
Appliquer tous les manifests k8s:

```bash
kubectl apply -f k8s/ --namespace=paytogether
```

Ceci va cr√©er les d√©ploiements, services et ingresses (assurez-vous que vos enregistrements DNS pointent vers l'IP publique de l'ingress controller).

## Remarques
- Les noms de domaines configur√©s dans les ingresses sont:
  - Front: `dev.dealtogether.ca`
  - BFF: `devbff.dealtogether.ca`
  - Registry: `registry.dealtogether.ca`

- Le `Jenkinsfile` est configur√© pour construire, tagger et pousser vers `14152021/dealtogether` et mettra √† jour les d√©ploiements via `kubectl set image`.

Si vous souhaitez que je g√©n√®re des manifests utilisant directement les variables d'image (e.g., Deployment avec imagePullPolicy: IfNotPresent et un placeholder pour image) ou ajouter TLS pour les ingress, dites-moi et je m'en occupe.

## D√©pannage : acc√®s externe via Ingress

Si vous ne parvenez pas √† acc√©der au front via `dev.dealtogether.ca`, suivez ces √©tapes de diagnostic depuis une machine ayant acc√®s au cluster (ou depuis une machine distante pour tester l'IP publique) :

1) V√©rifier l'√©tat de l'Ingress et l'IP expos√©e :

```bash
kubectl get ingress -n paytogether
kubectl describe ingress front-ingress -n paytogether
```

Attendu : l'Ingress doit appara√Ætre avec une adresse IP ou un hostname dans la colonne `ADDRESS` (ou √™tre pris en charge par le controller). Si l'ADDRESS est vide, l'Ingress controller ne fournit pas d'IP externe.

2) V√©rifier le controller NGINX (namespace commun : `ingress-nginx` ou `kube-system`) :

```bash
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx
```

Cherchez un `Service` du controller de type `LoadBalancer` (avec EXTERNAL-IP) ou `NodePort` si vous avez expos√© manuellement. Si vous n'avez pas d'EXTERNAL-IP, vous devez soit :
- installer MetalLB (pour bare-metal) et configurer une IP pool, ou
- utiliser un service LoadBalancer fourni par votre cloud, ou
- exposer le controller via `NodePort` et ouvrir le port sur votre firewall/routeur.

3) V√©rifier que le service et les endpoints du front existent :

```bash
kubectl get svc front-service -n paytogether
kubectl get endpoints front-service -n paytogether
kubectl get pods -l app=front -n paytogether
```

Attendu : le service doit avoir des endpoints list√©s. Si `endpoints` est `<none>`, le selector du Service n'est pas align√© avec les labels des Pods.

4) Tester depuis l'ext√©rieur (remplacez l'IP par `31.97.132.132`) :

```bash
# Test HTTP en envoyant l'en-t√™te Host pour simuler le domaine
curl -v -H "Host: dev.dealtogether.ca" http://31.97.132.132/

# Si votre DNS est configur√© pour pointer dev.dealtogether.ca vers l'IP


# V√©rifier la r√©solution DNS
dig +short dev.dealtogether.ca
nslookup dev.dealtogether.ca
```

Interpr√©tation rapide :
- si `curl -v -H "Host: ..." http://31.97.132.132/` retourne 200 ou la page du front, le controller re√ßoit le trafic et l'Ingress fonctionne ; le probl√®me est au niveau DNS externe (ou propagation) ;
- si `curl` n'atteint pas l'IP (timeout ou connection refused), le port 80/443 est bloqu√© par un firewall ou l'Ingress controller n'√©coute pas sur l'IP publique ;
- si `curl` retourne 404, v√©rifiez les r√®gles d'Ingress (`kubectl describe ingress ...`) et les `paths` d√©finis.

5) V√©rifier les logs du controller NGINX pour erreurs :

```bash
# Remplacez <deployment-name> par le nom du d√©ploiement du controller (ex: ingress-nginx-controller)
kubectl logs -n ingress-nginx deploy/ingress-nginx-controller
kubectl logs -n ingress-nginx <pod-name>
```

6) Test rapide d'acc√®s au service front dans le cluster :

```bash
# depuis une machine qui a kubectl configur√©
kubectl port-forward svc/front-service 8080:80 -n paytogether &
# puis dans un autre terminal
curl -v http://localhost:8080/
```

Si le port-forward fonctionne et que vous obtenez la page, les pods et le service sont OK ‚Äî le probl√®me est entre l'Ingress controller et l'ext√©rieur.

Points fr√©quents de blocage et corrections propos√©es :
- L'Ingress controller n'a pas d'EXTERNAL-IP (bare-metal) : installez MetalLB ou changez strat√©gie d'exposition (NodePort + ouvrir firewall) ;
- DNS incorrect ou non propag√© : v√©rifiez que `dev.dealtogether.ca` pointe bien vers `31.97.132.132` ;
- Firewall/iptables du serveur qui bloque 80/443 : ouvrez les ports 80/443 sur la VM/routeur public ;
- Service selector mismatch : v√©rifier que le `Service` s√©lectionne bien les `Pods` du front (labels `app: front`) ;
- Probes de readiness retournent non-ready : si votre SPA renvoie 200 sur `/` ou `/index.html`, ajustez le probe pour pointer vers une URL valide ;

Si vous voulez, je peux :
- analyser ensemble les sorties des commandes ci-dessus (collez-les ici),
- proposer des ajustements manuels pour MetalLB / NodePort si vous √™tes en environnement bare-metal,
- ajouter une route `/health` dans le front ou ajuster les probes √† `/index.html` si n√©cessaire ;

## Exposition des services en LoadBalancer (bare-metal)

Sur un cluster bare-metal ou VPS, `Service` de type `LoadBalancer` n√©cessite un composant r√©seau qui alloue des IP externes (ex: MetalLB). Ci-dessous les √©tapes pour installer MetalLB et configurer une plage d'adresses IP.

1) Installer MetalLB (version stable) :

```bash
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml
```

2) Cr√©er une ConfigMap MetalLB avec une plage d'adresses disponible dans votre r√©seau (exemple) :

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    address-pools:
    - name: default
      protocol: layer2
      addresses:
      - 31.97.132.240-31.97.132.250
EOF
```

3) V√©rifier que les Services `LoadBalancer` gagnent une EXTERNAL-IP :

```bash
kubectl get svc -n paytogether -o wide
kubectl describe svc front-service -n paytogether
```

4) Mettre √† jour votre DNS (ou /etc/hosts) pour pointer `dev.dealtogether.ca` vers l'IP expos√©e par MetalLB.

Supprimer Traefik (si pr√©sent)

Si vous aviez Traefik install√© et que vous voulez le supprimer pour utiliser NGINX Ingress :

```bash
# exemple si install√© via Helm
helm uninstall traefik -n traefik
kubectl delete namespace traefik
```

---

## üîÑ Gestion de base de donn√©es avec Liquibase

PayToGether utilise **Liquibase** pour g√©rer les versions du sch√©ma de base de donn√©es.

### Avantages
- ‚úÖ Versioning complet du sch√©ma de base de donn√©es
- ‚úÖ Tra√ßabilit√© de toutes les modifications
- ‚úÖ Rollback possible en cas de probl√®me
- ‚úÖ Synchronisation automatique au d√©marrage
- ‚úÖ Gestion multi-environnements (dev/hml/prod)

### Documentation
- üìÑ **[LIQUIBASE_INTEGRATION.md](LIQUIBASE_INTEGRATION.md)** - R√©sum√© de l'int√©gration
- üìÑ **[.github/documentation/LIQUIBASE_GUIDE.md](.github/documentation/LIQUIBASE_GUIDE.md)** - Guide complet
- üìÑ **[.github/documentation/LIQUIBASE_AIDE_MEMOIRE.md](.github/documentation/LIQUIBASE_AIDE_MEMOIRE.md)** - Aide-m√©moire rapide
- üìÑ **[.github/documentation/LIQUIBASE_BONNES_PRATIQUES.md](.github/documentation/LIQUIBASE_BONNES_PRATIQUES.md)** - Conventions du projet
- üìÑ **[.github/documentation/EXEMPLE_AJOUT_ENTITE_COMMANDE.md](.github/documentation/EXEMPLE_AJOUT_ENTITE_COMMANDE.md)** - Exemple pratique complet

### Sch√©ma actuel (v1.0.0)
Le sch√©ma initial comprend :
- **9 tables principales** : `utilisateur`, `categorie`, `deal`, `publicite`, `image_deal`, `image_utilisateur`, `image`, `deal_participants`, `deal_points_forts`
- **8 cat√©gories pr√©-remplies** : √âlectronique, Mode, Alimentation, Maison, Sports, Beaut√©, Services, Voyage
- **15+ index de performance** sur les colonnes critiques
- **Donn√©es de test** pour le d√©veloppement (utilisateurs, deals, publicit√©s)

### Configuration
Liquibase est configur√© pour s'ex√©cuter automatiquement au d√©marrage de l'application. La configuration se trouve dans :
- `modules/bff/bff-configuration/src/main/resources/application.properties`
- `modules/bff/bff-configuration/src/main/resources/db/changelog/`

### Migration depuis Hibernate DDL Auto
Si vous aviez une base existante, consultez la section "Migration" dans [LIQUIBASE_INTEGRATION.md](LIQUIBASE_INTEGRATION.md).

---

